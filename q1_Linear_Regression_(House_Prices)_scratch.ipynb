{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sl0E-5cJSEeF"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "data = {\n",
        "    'size_sqft': [1200, 1500, 1000, 1800, 2000],\n",
        "    'bedrooms': [2, 3, 1, 4, 3],\n",
        "    'age_years': [5, 10, 2, 15, 8],\n",
        "    'price': [250000, 350000, 200000, 400000, 450000]\n",
        "}"
      ],
      "metadata": {
        "id": "MUP7Q0UMTGan"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (independent variables)\n",
        "X = np.array([\n",
        "    [1200, 2, 5],\n",
        "    [1500, 3, 10],\n",
        "    [1000, 1, 2],\n",
        "    [1800, 4, 15],\n",
        "    [2000, 3, 8]\n",
        "])\n",
        "\n",
        "# Target (dependent variable)\n",
        "y = np.array([250000, 350000, 200000, 400000, 450000])"
      ],
      "metadata": {
        "id": "PLXcaUgrTMxD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples and features\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = np.zeros(n_features)  # Start with zeros\n",
        "bias = 0                        # Start with zero"
      ],
      "metadata": {
        "id": "VR4CbUkFTPvN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define the Prediction Function\n",
        "# The prediction function calculates the predicted value for a given input using the current weights and bias.\n",
        "# y^=X⋅w+b\n",
        "def predict(X, weights, bias):\n",
        "    return np.dot(X, weights) + bias"
      ],
      "metadata": {
        "id": "1qTNePY3TTlf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Loss Function\n",
        "# The loss function measures how far the predictions are from the actual values.\n",
        "def compute_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)"
      ],
      "metadata": {
        "id": "1WEu_6i2TjbJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Gradients\n",
        "# To update the weights and bias, we compute their gradients with respect to the loss function.\n",
        "def compute_gradients(X, y_true, y_pred):\n",
        "    n_samples = X.shape[0]\n",
        "\n",
        "    # Gradient for weights\n",
        "    dw = (1 / n_samples) * np.dot(X.T, (y_pred - y_true))\n",
        "\n",
        "    # Gradient for bias\n",
        "    db = (1 / n_samples) * np.sum(y_pred - y_true)\n",
        "\n",
        "    return dw, db"
      ],
      "metadata": {
        "id": "stB4-6LYT2z7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Parameters\n",
        "# Using the gradients, we update the weights and bias using the Gradient Descent formula\n",
        "def update_parameters(weights, bias, dw, db, learning_rate):\n",
        "    weights -= learning_rate * dw\n",
        "    bias -= learning_rate * db\n",
        "    return weights, bias"
      ],
      "metadata": {
        "id": "8gw7ytxRT-aG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "def train_linear_regression(X, y, learning_rate=0.00000001, n_iterations=1000):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Initialize weights and bias\n",
        "    weights = np.zeros(n_features)\n",
        "    bias = 0\n",
        "\n",
        "    # Training loop\n",
        "    for iteration in range(n_iterations):\n",
        "        # Step 1: Make predictions\n",
        "        y_pred = predict(X, weights, bias)\n",
        "\n",
        "        # Step 2: Compute loss\n",
        "        loss = compute_loss(y, y_pred)\n",
        "\n",
        "        # Step 3: Compute gradients\n",
        "        dw, db = compute_gradients(X, y, y_pred)\n",
        "\n",
        "        # Step 4: Update weights and bias\n",
        "        weights, bias = update_parameters(weights, bias, dw, db, learning_rate)\n",
        "\n",
        "        # Print progress every 100 iterations\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"Iteration {iteration}: Loss = {loss}\")\n",
        "\n",
        "    return weights, bias"
      ],
      "metadata": {
        "id": "D1QOJTmDUBPh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we can train the model and evaluate its performance.\n",
        "# Train the model\n",
        "weights, bias = train_linear_regression(X, y, learning_rate=0.00000001, n_iterations=1000)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = predict(X, weights, bias)\n",
        "\n",
        "# Evaluate the model\n",
        "def r2_score(y_true, y_pred):\n",
        "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "    return 1 - (ss_residual / ss_total)\n",
        "\n",
        "mse = compute_loss(y, y_pred)\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(\"Final Weights:\", weights)\n",
        "print(\"Final Bias:\", bias)\n",
        "print(\"Predicted Prices:\", y_pred)\n",
        "print(\"Actual Prices:\", y)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R² Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ4ECTqRUSh5",
        "outputId": "a8fecd01-7761-456a-f2c6-3651b9d963b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss = 117500000000.0\n",
            "Iteration 100: Loss = 1152040527.4588053\n",
            "Iteration 200: Loss = 222841492.2691247\n",
            "Iteration 300: Loss = 215419425.84812054\n",
            "Iteration 400: Loss = 215359011.72488028\n",
            "Iteration 500: Loss = 215357390.5081233\n",
            "Iteration 600: Loss = 215356238.8579763\n",
            "Iteration 700: Loss = 215355090.98264375\n",
            "Iteration 800: Loss = 215353943.16213894\n",
            "Iteration 900: Loss = 215352795.36675373\n",
            "Final Weights: [221.70110849   0.4359256    1.46065043]\n",
            "Final Bias: 0.11373059538890858\n",
            "Predicted Prices: [266049.61901821 332567.69074202 221704.57944394 399085.76246584\n",
            " 443415.32368461]\n",
            "Actual Prices: [250000 350000 200000 400000 450000]\n",
            "Mean Squared Error (MSE): 215351647.59624988\n",
            "R² Score: 0.9749591107446222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9Fgi5BzUWj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}